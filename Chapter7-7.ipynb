{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a8d2c8",
   "metadata": {},
   "source": [
    "In this program, we use logistic regression to see how the features could affect the prob of 1, i.e. exit, and also do the sklearn logistic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617ee135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6deff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Dataset\n",
    "data = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80540e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating Dependent Variable Vectors\n",
    "Y = data.iloc[:,-1].values\n",
    "X = data.iloc[:,3:13]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98c381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    1\n",
      "9996    1\n",
      "9997    0\n",
      "9998    1\n",
      "9999    0\n",
      "Name: Gender, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Generating Dependent Variable Vectors\n",
    "Y = data.iloc[:,-1].values\n",
    "X = data.iloc[:,3:13]\n",
    "X['Gender']=X['Gender'].map({'Female':0,'Male':1})\n",
    "### above is used instead of a more complicated package involving -- from sklearn.preprocessing import LabelEncoder\n",
    "### converts Female -- 0, Male -- 1, i.e. hot-encoding categorical variables\n",
    "print (X['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e436f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Categorical variable Geography\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct =ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n",
    "X = np.array(ct.fit_transform(X))\n",
    "### Geography is transformed into France -- 1,0,0; Spain -- 0,0,1; Germany -- 0,1,0.\n",
    "### Moreover -- this encoded vector of ones-zeros is now put in first 3 cols. Credit Score pushed to 4th col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3166a509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>France</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Germany</th>\n",
       "      <th>CrScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Products</th>\n",
       "      <th>CrCard</th>\n",
       "      <th>Active</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   France  Spain  Germany  CrScore  Gender   Age  Tenure    Balance  Products  \\\n",
       "0     1.0    0.0      0.0    619.0     0.0  42.0     2.0       0.00       1.0   \n",
       "1     0.0    0.0      1.0    608.0     0.0  41.0     1.0   83807.86       1.0   \n",
       "2     1.0    0.0      0.0    502.0     0.0  42.0     8.0  159660.80       3.0   \n",
       "3     1.0    0.0      0.0    699.0     0.0  39.0     1.0       0.00       2.0   \n",
       "4     0.0    0.0      1.0    850.0     0.0  43.0     2.0  125510.82       1.0   \n",
       "\n",
       "   CrCard  Active     Salary  \n",
       "0     1.0     1.0  101348.88  \n",
       "1     0.0     1.0  112542.58  \n",
       "2     1.0     0.0  113931.57  \n",
       "3     0.0     0.0   93826.63  \n",
       "4     1.0     1.0   79084.10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert X to dataframe X1\n",
    "X1 = pd.DataFrame(X)\n",
    "### Note there are 12 features including onehotencoder for the Geography feature-- \n",
    "### The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme\n",
    "### Renaming columns so they appear as variable names in regression output table\n",
    "X1.columns = ['France', 'Spain','Germany','CrScore','Gender','Age','Tenure','Balance','Products','CrCard','Active','Salary']\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "814997e4-1405-4f6e-8d5a-817d4fbbd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performing Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef915ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850b84b",
   "metadata": {},
   "source": [
    "We call fit_transform() method on our feature data X. Each feature in the training\n",
    "set is scaled to mean 0, variance 1. In sklearn.preprocessing.StandardScaler(), \n",
    "centering and scaling happens independently on each feature. The fit method is calculating\n",
    "the mean and variance of each of the features present in the data. The transform method\n",
    "is transforming all the features using the respective feature's mean and variance that are\n",
    "calculated in the statement. In cross-sectional feature data, we can do same mean, sd\n",
    "transforms of each feature before shuffling into train and test set, since each \n",
    "random shuffling should be invariant to the scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708f597",
   "metadata": {},
   "source": [
    "Logit regression basically finds the max log likelihood of Log L = sum_i { Y_i x Ln F(b'X_i) + (1-Y_i) x Ln (1-F(b'X_i)) }\n",
    "and F(b'X_i) = 1/(1+exp(-b'X_i)) is Prob (Y_i=1). Note X_i increases makes Prob(Y_i=1) increases to 1, while X_i decreases makes Prob(Y_i=1) decreases to 0. Logit (logistic) regression below shows coeff estimates of b. Note also max log L is minimizing loss function minus sum_i { Y_i x Ln F(b'X_i) + (1-Y_i) x Ln (1-F(b'X_i)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b03daac4-2a30-409e-9ad0-9c69ebdf2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e27e654b-0f9f-49e3-a63f-de5d2cb151da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12256364  0.21736622 -0.07633822 -0.05348885 -0.26533692  0.74822048\n",
      "  -0.02792812  0.16934491 -0.04022361 -0.03669323 -0.54902098  0.01605643]] [-1.6584463]\n"
     ]
    }
   ],
   "source": [
    "Lresult = LogReg.fit(X_train, Y_train)\n",
    "print(Lresult.coef_, Lresult.intercept_)\n",
    "### SKlearn logisticRegression adds regularization so the results\n",
    "###  are a bit different from the statsmodel package above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf2aad9d-2b57-489c-bdbe-b2b6cfdc4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lpredict=LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc063c46-4d05-4a59-8766-7f8e792d5b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "### Using Score method to obtain accuracy (% correct prediction) of model\n",
    "score = LogReg.score(X_test,Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2620c574-7b9c-482d-aac5-5a77ef13ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Lpredict) ### shows prediction of 1 or else of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e5592e-6fe3-4a83-b986-f37e159d3def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lpredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09745e76-43cf-44c1-bde1-92281d3214e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625 0.8125\n"
     ]
    }
   ],
   "source": [
    "Lpredict1=Lpredict\n",
    "Lpredict1[Lpredict1==0]=-1\n",
    "Y_test1=Y_test\n",
    "Y_test1[Y_test1==0]=-1\n",
    "J1=np.multiply(Y_test1.T,Lpredict1.T)  ### element by element multiplication\n",
    "c1=np.count_nonzero(J1 > 0) \n",
    "print(c1,c1/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43f1db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.429076\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 8000\n",
      "Model:                          Logit   Df Residuals:                     7987\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Thu, 05 Dec 2024   Pseudo R-squ.:                  0.1490\n",
      "Time:                        10:02:36   Log-Likelihood:                -3432.6\n",
      "converged:                      False   LL-Null:                       -4033.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.935e-250\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Constant      -1.6590      0.035    -47.936      0.000      -1.727      -1.591\n",
      "France        -0.1227        nan        nan        nan         nan         nan\n",
      "Spain          0.2174        nan        nan        nan         nan         nan\n",
      "Germany       -0.0764        nan        nan        nan         nan         nan\n",
      "CrScore       -0.0535      0.030     -1.771      0.077      -0.113       0.006\n",
      "Gender        -0.2656      0.030     -8.768      0.000      -0.325      -0.206\n",
      "Age            0.7491      0.030     24.800      0.000       0.690       0.808\n",
      "Tenure        -0.0280      0.030     -0.924      0.355      -0.087       0.031\n",
      "Balance        0.1695      0.036      4.715      0.000       0.099       0.240\n",
      "Products      -0.0402      0.030     -1.319      0.187      -0.100       0.020\n",
      "CrCard        -0.0367      0.030     -1.220      0.222      -0.096       0.022\n",
      "Active        -0.5498      0.032    -16.996      0.000      -0.613      -0.486\n",
      "Salary         0.0161      0.030      0.530      0.596      -0.043       0.076\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vista\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(Y_train,sm.add_constant(X_train))\n",
    "result=logit_model.fit()\n",
    "#print(result.summary())\n",
    "print(result.summary(xname=['Constant','France', 'Spain','Germany','CrScore','Gender','Age','Tenure','Balance','Products','CrCard','Active','Salary']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
